Discussion
==========

In this section, we first give an intuitive interpretation of how the Global Connectivity Estimation algorithm works. Then, we present our OpenCL-architected solution: Oclptx. We then show the results of Oclptx, comparing both the correctness of the paths as well as the speed to the old tracking software.

Algorithmic Theory
------------------

The tracking algorithm follows the following routine:

#. Load multiple sets of fiber parameters created by the bedpostx step (:math:`F, \phi, \theta`). These parameters are the anisotropy and vector field parameters, respectively.
#. Repeatedly drop imaginary “particles” into the space of the brain. In this step, the algorithm treats the estimated fiber directions as flow directions.
#. Step through the brain via the flow directions, a fixed distance at a time, until it some stopping conditionv is reached. The stopping condition is typically a user-defined mask.

The location of particles is determined by user-defined seeds. Seeds can be defined individual in text-format, or as a series of volumes and surfaces which the program automatically iterates through. For each seed, many particles are instantiated. Each particle begins at a random location within a sphere of its seed point. Paths are then interpolated from this starting location, using the fiber distribution. Since the particle does not have an initial direction to help it decide which way to follow the first non-directional fibre, typically it will be run twice---once in each direction. The relation between seeds, particles, and paths is shown in Figure 3.1.

.. _particle:

.. figure:: images/seed_part_path.pdf

  Relation between seeds, particles, and paths.

As the particle is travelling through voxels, the adjacent voxel to sample the direction from is randomly selected.  This selection is inversely proportional to the distance from the nearest vertex.  Once we know the next vertex, a fiber orientation must be determined.  There are several options for this, all of which are selected by the user at start time.  Either a preferred direction is chosen, or the sampler chooses one of the following options: random with error weights, random above a given error threshold, or entirely random.  This process is shown in Figure 3.2.

.. _pathing:

.. figure:: images/pathing.pdf

  Interpolation and Pathing

Methods and Architecture
------------------------

Our Oclptx fits in as a seperate module in the FSL suite (Figure 3.3). The intention is that we take identical command-line parameters from a user using Oclptx as one using Probtrackx. These parameters are primarily Bedpostx data, along with brainmasks, and other user-specified options.

.. _fsl:

.. figure:: images/fsl.png

  Simplified diagram of FSL: BedpostX results are parsed and converted for use on the GPU via a "Samplemanager" class.

Within Oclptx, we architect our code around three steps in the pipeline: Initialization, Interpolation, and Reduction (Figure 3.4).

..
  .. _oclptx:

  .. figure:: images/oclptx.pdf

    Block diagram of the Oclptx pipeline. The :math:`F, \phi, \theta` parameters are read in via the initialization step, and then passed into the GPU interpolation and reduction scheme. Outdated. fix.

Initialization
^^^^^^^^^^^^^^
In the initialization step of our code, we do away with the abstracted data structures that store the incoming user-data in the old Probtrackx suite. Instead, we manage our data in a custom class called Samplemanager. We implemented this class to prevent the duplication of data containers that were used naively in the old probtrackx. Samplemanager interacts directly with the old probtrackx command-line-parser, reading in the myriad of data the user can input (for a complete list of the options, see Appendix section). Samplemanager's primary purpose is to store the static bedpostx and mask data, and provide access to them for the Oclptx routine.

It is worth mentioning that the time taken to initialize data does not factor into our speed computations when we present our results. We make this choice since initialization is done once and only once throughout the lifecycle of the program. (redundant, edit)

On the GPU, oclptx deals with two types of data: static data and dynamic particle data. Static data encapsulates any large structures that are written to the GPU once and which stay in VRAM until all computation is finished. This includes BedpostX diffusion parameter data, (anisotropy + directions), as well as any tracking masks. The following buffers are allocated to *each* available OpenCL GPU device during intialization (kernel access type specified):

* BedpostX parameter data: FA, Phi, Theta. By default, one fiber direction is copied to the device. Other directions are only copied if specified by the user (CL_MEM_READ_ONLY).

* Brain mask, (mandatory), (CL_MEM_READ_ONLY).

* Exclusion mask (optional), (CL_MEM_READ_ONLY).

* Termination mask (optional), (CL_MEM_READ_ONLY).

* Waypoint mask (optional), (CL_MEM_READ_ONLY).

* Global PDF (mandatory), (CL_MEM_READ_WRITE).

Of the user specified data, a significant amount of time is spent copying the parameter data. The mask data is all of the same dimension, and of unsigned short int type, so it does not use up many resources.

Out of all of these, the largest data to allocate by far is the diffusion parameter data. Sample BedpostX data may come in a variety of sizes, with respect to the voxel grid. For simplicity, oclptx will support any sample data which can fit in the vendor suggested CL_DEVICE_MAX_MEM_ALLOC_SIZE parameter for a particular GPU device. For example, sample data obtained from CFRI had dimensions of 256x271x121 (check this...not sure about the z value). With 32 bit float values, one principal direction of one type of parameter, (either f, phi, or theta), with 50 samples per paramater takes up ~920MB of VRAM. For consumer level GPU's, CL_DEVICE_MAX_MEM_ALLOC_SIZE is typically ~1/8 of total VRAM. So, for the sample size given, only higher end workstation cards with 6GB+ of VRAM will be able to allocate this memory. It is not suggested that the user force a higher CL_DEVICE_MAX_MEM_ALLOC_SIZE in the given OpenCL context, as this may lead to severe caching issues due to the nonsequential memory access patterns of the tracking algorithm.

Note: it is up to the user to ensure that their data will fit on the device.

During development, 16-bit fixed point encoding was attempted on the BedpostX data to compress it and lower memory requirements. FA data was encoded as 1:15, Phi data was encoded as 3:13 and theta data was encoded as 2:14 (bits before decimal : bits after decimal). Subsequent testing revealed a significant divergence from the deterministic ptx2 results, the total mean-square error of the test set went up by a factor of 10^4. As the main goal was to provide a precise, functionally equivalent port for CFRI, this functionality was shelved. However, should users run into severe memory limitations, this may be an acceptable solution.
..

  .. _oclptxhandler:

  .. figure:: images/oclptxhandler.png
      :scale: 50 %

      Make this a block diagram of OclEnv. Redo later.

After static data containers are allocated and synchronized by the OclEnv class, the remaining GPU memory is determined, in bytes, and that value is sent to OclPtxHandler, (mention something about memory risk fraction, etc). OclPtxHandler then determines, based on user-specified options, how much memory needs to be allocated per particle, and then simply maximizes the number of particles that will fit in the remaining memory. The following containers are allocated *per particle*:

* Current position, last step direction, and particle rng state values in a 64 bit aligned struct, (mandatory) (CL_MEM_READ_WRITE)
* Particle PDF mask: a binary mask of the global voxel space, unique to a single particle, (mandatory), (CL_MEM_READ_WRITE).
* particle path (optional): an array of size max_steps that contains the full particle path in the voxel space, this is potentially large, (CL_MEM_WRITE_ONLY).
* particle waypoints (optional): for every included waypoint mask there are that many ushort per particle to indicate whether it has passed through each mask.
* particle loopcheck (optional): an array of last flow directions taken in a voxel in the loopcheck voxel space. This is potentially a massive array, (optional), (CL_MEM_READ_WRITE).

To mirror the "dual direction" functionality in probtrackx, (where every particle is instantiated twice, and starts tracking in opposite directions), the starting "dr" of each particle is instantiated as {+/-1., 0., 0.}. The specifics of how all the containers above are used in tracking is discussed in the next section.

Interpolation
^^^^^^^^^^^^^

(change this section name to tracking)

For every reduction step, when a batch of particles is sent to the GPU(s) for processing, two distinct kernels operate on that batch: interpolation and summing. At its core, oclptx aims to mirror exactly the functionality of probtrackx. With respect to interpolation, every operation in the interpolation GPU kernel aims to mirror functionality from the Streamline::Streamlines method in ptx2. All of the tracking constraints, (with the exception of prefdir), and options are implemented. The interpolation kernel work range is simply the space of queued particles. The summing kernel first checks whether a particle is completely finished tracking, (that it has terminated and that its path is to be included in the pdf output). If the particle is valid, its individual pdf mask is parsed and all voxels it passes through are incremented by 1 in the global pdf. To reduce the need for atomic operations, the summing kernel work range is actually the global voxel space, separated into 32 voxel regions. Each summing thread obtains data from all valid particles, and performs summing on it's particular section.

..
  .. _interpolation_flow:

  .. figure:: images/interpolation_flow.png
      :scale: 50 %

      Basic overview of tracking algorithm kernel.

To reduce performance penalties, optional tracking steps in either kernel are not compiled if they are unused. This is to reduce any penalties from repeatedly calling conditional statements in the kernel, which decrease performance as the particle count increases.

Interpolation
.............

Interpolation on the GPU is done on a per-particle basis. Each thread processes the stepping of a single particle. Upon startup, the last position, rng state, and unit jump direction are loaded, and then tracking begins. By default, tracking is probabilistic, with random number generation being performed by a modified Tausworth/LFSR algorithm, (in rng.cl) on a 8x64 bit particle rng seed state, which is seeded host-side on startup. The returned rng value is always a 64bit unsigned integer. Deterministic tracking can be enabled via CLI, in which case this routine always returns 0. Any normalization, to fit the rng result in a desired interval, is done in the interpolation kernel explicitly. If a particle terminates tracking for any reason, (even normal completion), it is assigned an exit code as defined in attrs.h. This is used by the summing kernel and reduction algorithms to determine how to proceed.

Once a particle is loaded into VRAM, and the maximum number of steps per kernel run are specified, probabilistic tracking proceeds in the following manner:

#.  **Volume Fraction Criterion** - the floor() of the current particle position is designated as the "root" vertex in the voxel space. In each direction, an rng is generated in the range [0, 1.0]. If the particle position, subtracting the root vertex is greater than this rng value in a particular dimension, that dimension is incremented by 1 in the vertex space. This method biases particle selection towards the closest vertex, while still allowing for selection of the farther vertices in the voxel. The incremented vertex is referred to as the "select vertex".

#.  **Sample Selection** - Random selection of BedpostX parameter sample set. This is simply the mod (num_samples) of the 64 bit rng value.

#.  **Stepping** - In general, the individual particle stepping mirrors the particle::jump method from ptx2. When a sample is selected, the new jump direction is aligned with the previous jump direction, to reduce erratic pathing, (does not make sense from a biological perspective).

    #. **Anisotropic Constraint** (optional)- Implemented in the same way as in Streamline::Streamline. If the FA value selected is less than some rng in [0.0, 1.0], the stepping simply terminates with exit code ANISO_BREAK. This particle will still be included in the output pdf.
    #. **Standard (Euler) Interpolation** (mandatory)- The standard interpolation is done with the simple euler method

    .. math::
      Y_{n+1} = Y_n + h \cdot F (Y_n) \quad  | \quad F(Y) = \dot{Y}
    where h is the user specified step length parameter. F(Y) returns a unit vector with orientation specified by the particular BedpostX parameter samples.
    #. **Improved Euler Interpolation** (optional) - If desired, the user can specify a more precise method of interpolation: Improved/Modified Euler, (aka Runge-Kutta 2). This is a two-step method which interpolates as follows:

    .. math::
      Y_{n+1}^\star = Y_n + h \cdot F (Y_n)

      Y_{n+1}= Y_{n} + \frac{h}{2}(F(Y_n) + F(Y_{n+1}^\star)
    This method generally produces less erattic results and is more stable.

Regardless of the options, the resultant :math:`Y_{n+1}` is added to the old particle position and stored as as temporary position, to be evaluated futher. (indentation is fucked here, figure it out later)

#.  **Masks / Termination Conditions** - masks that are checked

    #. **Brain Mask** (mandatory)
    #. **Exclusion Mask** (optional)
    #. **Termination Mask** (optional)
    #. **Waypoint Mask(s)** (optional)
    #. **Curvature Threshold** (mandatory) - After every FINAL NORMALIZED dr is termined.

#.  **Updating Output Data** - If the temporary position passes all of the specified checks, it is considered valid and the particle state's position and last jump direction are updated.

    #. **Particle Pdf Update** - If the temporary position is accepted, its position in the voxel space is determined by an integer mapping. Then, after some bit shifting, the relevant bit in the particle's pdf mask is assigned a value of 1, (mask |= 1).
    #. **Particle Path Update** (optional) Shoud the user specify that pathing information is to be saved, the particle's new position is writing

If, at the end of each loop iteration, the max_steps_per kernel value is reached, the tracking stops, and the particle is assigned the BREAK_MAXSTEPS termination code. This means that tracking will continue on the next kernel run. The interpolation kernel's runtime is a function of the interpolation steps taken per reduction step, as well as the number of particles queued, which relates specifically to the number of available stream processor cores.

Summing
.......

Currently, once interpolation *finishes*, the summing kernel is queued immediately after. Each thread of the summing kernel operates on a size 32 section of the voxel space and sums the individual particle binary PDF entries into the global pdf. Inside each kernel, every particle is checked for the appropriate termination conditions. If the conditions are satisfied, that particles 32 bit binary mask for that thread's section of the pdf is added to the global pdf. The following operations are performed for each particle:

#.  **Check Inclusion Conditions** - Depending on the particle's progress during interpolation, its individual pdf mask may or may not be added to the global total when the summing kernel is executed.

    #. **Termination** - If the particle has terminated, the termination code has an integer value > 0. Only these are ever considered for summing.
    #. **Waypoint Condition** - For a particle that has finished tracking, and with waypoint mask use enabled, it is checked whether the particle has pass through all of the waypoints. This condition can either be specified as an AND or OR operation, the former requiring passage through all masks, and the latter requiring passage through only one. Whatever the condition, the particle must meet it to be included in the pdf.
    #. **Exclusion** - If the termination code is > 0, and not any of: BREAK_INIT, BREAK_INVALID, STILL_FINISHED, the particle is not added to the pdf.

#. **Summing** - Each binary mask section of each *satisfactory* particle is summed and the global pdf voxels are incremented appropriately. The individual particle masks are bit masks, and so, for a particular spatial voxel, the aggregate sum is obtained by shiting and summing individual particle bit masks in a __local memory container and then added to the global pdf at particle completion.

The summing kernel is expected to take longer to run than the interpolation kernel for even very large particle sets as it is O(V), (the number of voxels, XxYxZ), which can reach into the tens of millions for large voxel dimensions.

Reduction
^^^^^^^^^

Reduction and Segmentation optimizes the use of GPU resources. Instead of naively running threads until the last one converges, the code is segmented. A segmentation container holds the maximum number of steps per Kernel, so that all threads in a given Kernel will stop interpolating at the MaxSteps number for that Kernel. In previous implementations, when the Kernel terminates, the thread evaluations consolidated CPU-side, where we determine what paths have been calculated completely. New kernels are launched only for the unfinished paths.

Our task with reduction is to implement a multi-threaded version of this process.

TODO: JEFF
THIS IS A BASIC OVERVIEW OF YOUR PROCESS. 2-3 PARAGRAPHS MAX. (Feel free to modify what I've written, just filling in what I know and what I salvaged).

.. _oclptxdatadiagram:

.. figure:: images/datadiagram.pdf

    Multiple GPU interpolation workflow.


Results and Analysis
--------------------

Implementing the aforementioned pipeline, we have arrived at a GPU-based tracking system that can be validated for both correctness as well as speed. The results presented in this section are organized as follows:

* We first show a deterministic comparison between Oclptx and Probtrackx, proving validity as well as computation speed increase.
* Next, we show the fully probabilistic result of Oclptx using our custom PRNG routine.
* Finally, we present our work on multi-threaded reduction.

We recognize that proving convergence on the probabilistic scenario is necessary to completely prove correctness. While we can produce probablistic results, time did not allow for us to set up the statistical t-tests necessary for validation. Our sponsor has offered to complete this task himself, given that a deterministic match is the critical step.

Deterministic Comparison of Oclptx and Probtrackx
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

To test the convergence of our results with expected behaviour, we modified the source code of Probtrackx (ptx2) such that it does not seed randomly. Instead, we forced ptx2 to seed at a predefined location in the brain mask, and we seeded our Oclptx at that same location in the same data set. Hence, by proving that in this deterministic scenario our interpolation algorithm produces exactly the same set of streamlines as the old code, we prove that our algorithm matches the expected results.

We show these results in :ref:`deterministiccomp`. In this data set, we use 1000 seed points and generated 2000 particles, with a maximum of 2000 steps per path. These parameters give us approximately 4 million points. We then sum over these points to determine the error between the results, :math:`\chi ^ 2`, as follows:

:math:`\chi^2 =  \sum (r^{(1)}_i - r^{(2)}_i)^2  =  O(10^{-11}) \rightarrow  { \langle \chi^2 \rangle } \simeq {O(10^{-13})}`

.. _deterministiccomp:

.. figure:: images/deterministiccomp.pdf

    Deterministic comparison of paths generated by Probtrackx (ptx2) and Oclptx, plotted with Python.


Thus, we have a statistcally negligible error. The differences we have can be accounted for if we consider deviations in how the GPU calculates quantities such as sine or cosine. Fundementally, we have shown that the deterministic results of the two pipelines are identical.

Next, we compare the run time of Oclptx against that of ptx2. For a 4000 particle sample dataset, a deterministic run of ptx2 has an average computation time of **43 seconds** from the point of beginning to interpolate to the point of completion. Oclptx, for the same dataset, has an average tracking time of **500-1500 milliseconds**. The following table compares the two algorithms for various particle sizes.

===========  =========  ===========
Sample Size  Ptx2 Time  Oclptx Time
===========  =========  ===========
4000          43s         1000ms
===========  =========  ===========

    Computation times of Oclptx and Ptx2 compared.

TODO: STEVE This is stuff for you; I wrote to the best of my knowledge and research on our results. You can modify/add as needed. Discuss the significance of the results only within the problem space (not for the greater good of humanity or someshit). NO RECOMMENDATIONS HERE

TODO (steve): going to perform some actual timing benchmarking tonight and include 3-4 plots here.

Probabilistic Results of Oclptx
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

TODO STEVE: Describe the results and show the pictures of the biased tracking. I've already stated in the opening that we don't test against the old PTX2 on this step. Here you can expand on what tests NEED to be done by Danny. NO RECOMMENDATIONS HERE

.. _probibilistic1:

.. figure:: images/probibilistic1.pdf

    Caption here as needed

TODO JEFF: PRNG routine. Describe the results, not much of the process. Your ppt slide has a good level of detail for that. NO RECOMMENDATIONS HERE

.. _prng:

.. figure:: images/prng.png

    Caption here as needed

Multi-Threaded Reduction
^^^^^^^^^^^^^^^^^^^^^^^^

TODO JEFF: If we are at a point to describe integration with Oclptx, then we describe the results of the integration. Focus on Speed and Correctness (compared to the non-multithreaded version). If we are NOT, then the results are the results of your research with collatz. Focus on TEST results. NO RECOMMONDATIONS HERE


