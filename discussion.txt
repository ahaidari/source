Discussion
==========

In this section, we first give an intuitive interpretation of how the Global Connectivity Estimation algorithm works. Then, we present our OpenCL solution: oclptx. We then show the results of oclptx, comparing both the correctness of the paths as well as the speed to the old tracking software.

Algorithmic Theory
------------------

The tracking algorithm follows the following routine:

#. Load multiple sets of fiber parameters created by the bedpostx step (:math:`F, \phi, \theta`). These parameters are the anisotropy and vector field parameters, respectively.
#. Repeatedly drop imaginary “particles” into the space of the brain. In this step, the algorithm treats the estimated fiber directions as flow directions.
#. Step through the brain via the flow directions, a fixed distance at a time, until it some stopping conditionv is reached. The stopping condition is typically a user-defined mask.

The location of particles is determined by user-defined seeds. Seeds can be defined individual in text-format, or as a series of volumes and surfaces which the program automatically iterates through. For each seed, many particles are instantiated. Each particle begins at a random location within a sphere of its seed point. Paths are then interpolated from this starting location, using the fiber distribution. Since the particle does not have an initial direction to help it decide which way to follow the first non-directional fibre, typically it will be run twice---once in each direction. The relation between seeds, particles, and paths is shown in Figure 3.1.

.. _particle:

.. figure:: images/seed_part_path.pdf

  Relation between seeds, particles, and paths.

As the particle is travelling through voxels, the adjacent voxel to sample the direction from is randomly selected.  This selection is inversely proportional to the distance from the nearest vertex.  Once we know the next vertex, a fiber orientation must be determined.  There are several options for this, all of which are selected by the user at start time.  Either a preferred direction is chosen, or the sampler chooses one of the following options: random with error weights, random above a given error threshold, or entirely random.  This process is shown in Figure 3.2.

.. _pathing:

.. figure:: images/pathing.pdf

  Tracking and Pathing

Methods and Architecture
------------------------

Oclptx fits in as a separate module in the FSL suite (Figure 3.3). The intention is that we take identical command-line parameters from a user using oclptx as one using probtrackx. These parameters are primarily bedpostx data, along with brainmasks and other user-specified options.

.. _fsl:

.. figure:: images/fsl.png

  Simplified diagram of FSL: bedpostX results are parsed and converted for use on the GPU via a "samplemanager" class.

Within oclptx, we architect our code around three steps in the pipeline: Initialization, Tracking, and Reduction (Figure 3.4).

..
  .. _oclptx:

  .. figure:: images/oclptx.pdf

  Block diagram of the Oclptx pipeline. The :math:`F, \phi, \theta` parameters are read in via the initialization step, and then passed into the GPU interpolation and reduction scheme. TODO Steve: FIX

Initialization
^^^^^^^^^^^^^^

In the initialization step of our code, we manage our data in a custom class called samplemanager. We implemented this class to prevent the duplication of data containers that were used naively in the old probtrackx. Samplemanager interacts directly with the old probtrackx command-line-parser, reading in the myriad of data the user can input (for a complete list of the options, see the Appendix). Samplemanager's purpose is to store static bedpostx/mask data, and provide access to the data for the oclptx routine. It is worth mentioning that the time taken to initialize data does not factor into the speed computations presented in our results.

On the GPU, oclptx deals with two types of data: static data and dynamic particle data. Static data encapsulates any large structures that are written to the GPU once, and which stay in VRAM until all computations are finished. These include bedpostX diffusion parameter data as well as any tracking masks. The OclEnv class is responsible for managing static data. The following buffers are allocated to *each* available OpenCL GPU device during initialization:

* BedpostX parameter data: :math:`F, phi, theta`. By default, one fiber direction is copied to the device. Other directions are only copied if specified by the user.

* Brain mask, (mandatory).

* Exclusion mask (optional).

* Termination mask (optional).

* Waypoint mask (optional).

* Global PDF (mandatory).

The largest dataset to allocate on the GPU is the diffusion parameter data. Parameter data may come in a variety of sizes with respect to the voxel grid. Oclptx supports any sample dataset which can fit in the vendor suggested CL_DEVICE_MAX_MEM_ALLOC_SIZE parameter for a particular GPU device. For example, sample data obtained from CFRI has dimensions of 256x271x102. With 32-bit float values, one principal direction of one type of parameter (either f, phi, or theta) and 50 samples per parameter uses ~920MB of VRAM. For consumer level GPU's, CL_DEVICE_MAX_MEM_ALLOC_SIZE is typically ~1/8 of total VRAM. Therefore, for the sample size given, only higher end workstation cards with 6GB+ of VRAM will be able to allocate this memory. It is up to the user to ensure that their data will fit on the device.

  .. _oclptxhandler:

  .. figure:: images/oclptxhandler.png
      :scale: 50 %
      
    Make this a block diagram of OclEnv. TODO STEVE: REDO THIS

After static data containers are allocated and synchronized by the OclEnv class, the remaining GPU memory is determined in bytes, and that value is sent to OclPtxHandler. Next, OclPtxHandler uses user-specified options to determine how much memory needs to be allocated per particle, and subsequently maximizes the number of particles that will fit in the remaining memory. The following containers are allocated *per particle*:

* Current position, last step direction, and particle state values in a 64-bit aligned struct (mandatory).
* Particle PDF mask: a binary mask of the global voxel space, unique to a single particle (mandatory).
* particle path: an array of size max_steps that contains the full particle RNG path in the voxel space (optional).
* particle waypoints: for every user-specified waypoint mask there are that many ushort ints per particle to indicate whether it has passed through each mask (optional).
* particle loopcheck: an array of last flow directions taken in a voxel (optional).

To mirror the "dual direction" functionality in probtrackx (where every particle is instantiated twice, and starts tracking in opposite directions), the starting vector of each particle is instantiated as {+/-1., 0., 0.}. The specifics of how the containers above are used in tracking is discussed in the next section.

Tracking
^^^^^^^^

When a batch of particles is sent to the GPU(s) for processing, two distinct kernels operate on that batch: **interpolation** and **summing**. Every operation in the interpolation GPU kernel mirrors functionality from the Streamline::Streamlines method in probtrackx. The interpolation kernel's work range is simply the space of queued particles. The summing kernel first checks whether a particle is finished tracking; that it has terminated and that its path is to be included in the pdf output. If the particle is valid, its individual pdf mask is parsed and all of the voxels it passes through are incremented by 1 in the global pdf. To reduce the need for atomic operations, the summing kernel work range is actually the global voxel space separated into 32 voxel regions. Each summing thread obtains data from all valid particles, and performs summing on its particular section.

  .. _interpolation_flow:

  .. figure:: images/interpolation_flow.png
      :scale: 50 %

      Basic overview of tracking algorithm kernel.

Any optional tracking steps in the kernels are not compiled if they are unused. This is to reduce any penalties from repeatedly calling conditional statements in the kernel, which decrease performance as the particle count increases.

Interpolation
.............

Interpolation on the GPU is done on a per-particle basis. Each thread processes the stepping of a single particle. Upon startup, the last position, RNG seed value, and unit jump direction are loaded, and then tracking begins. By default, tracking is probabilistic, with random number generation performed by a modified Tausworth/LFSR algorithm. The returned RNG value is always a 64bit unsigned integer. Deterministic tracking can be enabled via the command line, in which case the RNG routine always returns 0. Any normalization to fit the RNG result into a desired interval is done in the interpolation kernel explicitly. If a particle terminates tracking for any reason, it is assigned an exit code as defined in attrs.h. The code used by the summing kernel and reduction algorithms to determine how to proceed.

When a particle is loaded into VRAM and the maximum number of steps per kernel run are specified, probabilistic tracking proceeds in the following manner:

#.  **Volume Fraction Criterion** - The floor() of the current particle position is designated as the "root" vertex in the voxel. In each direction, a random number is generated in the range [0.0, 1.0]. In a given :math:`x,y,z` dimension, if the difference between the particle position and the root vertex is greater than this random number, that dimensional component is incremented by 1 in the vertex space. This method biases particle selection towards the closest vertex while still allowing for selecting the further vertices in the voxel. The incremented vertex is referred to as the "select vertex".

#.  **Sample Selection** - Random selection of BedpostX parameter sample set. This is the mod(num_samples) of the 64 bit RNG value.

#.  **Stepping** - In general, individual particle stepping mirrors the particle::jump method from probtrackx. When a sample is selected, the new jump direction is aligned with the previous jump direction to reduce erratic pathing.

    #. **Anisotropic Constraint** (optional)- Implemented in the same way as in Streamline::Streamline in probtrackx. If the F value selected is less than some random number in [0.0, 1.0], the stepping simply terminates with exit code ANISO_BREAK. The particle will still be included in the output pdf.
    #. **Standard Euler Interpolation** (mandatory)- The standard interpolation is done with the simple Euler method:

    .. math::
      Y_{n+1} = Y_n + h \cdot F (Y_n) \quad  | \quad F(Y) = \dot{Y}
    where h is the user-specified step length parameter. F(Y) returns a unit vector with an orientation specified by the particular bedpostX parameter.
    #. **Improved Euler Interpolation** (optional) - A more precise, user-specified interpolation method. It is a two-step method which interpolates as follows:

    .. math::
      Y_{n+1}^\star = Y_n + h \cdot F (Y_n)

      Y_{n+1}= Y_{n} + \frac{h}{2}(F(Y_n) + F(Y_{n+1}^\star)
    This method generally produces less erratic results.
    
    Regardless of the options, the resultant :math:`Y_{n+1}` is added to the old particle position and stored as as temporary position to be evaluated further.

#.  Mask Checking (STEVE TODO: Define these please):

    #. Brain Mask(mandatory)
    #. Exclusion Mask (optional)
    #. Termination Mask (optional)
    #. Waypoint Mask(s) (optional)
    #. Curvature Threshold (mandatory)

#.  **Updating Output Data** - If the temporary position passes all of the specified checks, it is considered valid. The particle's position and last jump direction can be updated in two ways:

    #. **Particle Pdf Update** - If the temporary position is accepted, its position in the voxel space is determined by an integer mapping. Then, the relevant bit in the particle's pdf mask is assigned a value of 1 (mask |= 1).
    #. **Particle Path Update** (optional) Should the user specify that pathing coordinates are to be saved, the particle's new position is written to a file.

If, at the end of each loop iteration the max_steps_per kernel value is reached, then the tracking stops and the particle is assigned the BREAK_MAXSTEPS termination code. This means that tracking will continue on the next kernel run. The interpolation kernel's runtime is a function of the interpolation steps taken, as well as the number of particles queued.

Summing
.......

Once interpolation *finishes*, the summing kernel is queued immediately. Each thread of the summing kernel operates on a section of the voxel space. In each thread, every particle is checked for the appropriate termination conditions. If the conditions are satisfied, that particle's 32-bit entry pdf is added to the global pdf. The following operations are performed for each particle:

#.  **Check Inclusion Conditions** - As mentioned above, a particle's individual pdf mask may or may not be added to the global total when the summing kernel is executed. There are three possible conditions to check:

    #. **Termination** - If the particle has terminated, the termination code has an integer value > 0. Only these particles are considered for summing.
    #. **Waypoint Condition** - Only valid if the user provides Waypoint masks. For a particle that has finished tracking, we check whether the particle has passed through all of the waypoints. This condition can either be specified as an AND or OR operation: the former requires passage through all masks, and the latter requires passage through only one. Whatever the condition, the particle must meet it to be included in the pdf.
    #. **Exclusion** - If the termination code has an integer value > 0, and is not any of BREAK_INIT, BREAK_INVALID, STILL_FINISHED, then the particle is excluded. In other words, it is not added to the pdf.

#. **Summing** - Each binary mask section of each *included* particle is summed, and the global pdf voxels are incremented appropriately. The individual particle masks are bit masks. As such, for a particular voxel, the aggregate sum is obtained by shifting and summing individual particle bit masks in a local memory container. The result is then added to the global pdf at particle completion.

The summing kernel is expected to take longer to run than the interpolation kernel for large particle sets, as it is O(V) (the number of voxels, X*Y*Z). The complexity value can reach up to tens of millions for large voxel dimensions.

Reduction
^^^^^^^^^

Reduction and Segmentation optimizes the use of GPU resources. Instead of naively running threads until the last one converges, the code is segmented. A segmentation container holds the maximum number of steps per Kernel, so that all threads in a given Kernel will stop interpolating at the MaxSteps number for that Kernel. In previous implementations, when the Kernel terminates, the thread evaluations consolidated CPU-side, where we determine what paths have been calculated completely. New kernels are launched only for the unfinished paths.

Our task with reduction is to implement a multi-threaded version of this process.

TODO: JEFF
THIS IS A BASIC OVERVIEW OF YOUR PROCESS. 2-3 PARAGRAPHS MAX. (Feel free to modify what I've written, just filling in what I know and what I salvaged).

.. _oclptxdatadiagram:

.. figure:: images/datadiagram.pdf

    Multiple GPU interpolation workflow.


Results and Analysis
--------------------

Implementing the aforementioned pipeline, we have arrived at a GPU-based tracking system that can be validated for both correctness as well as speed. The results presented in this section are organized as follows:

* We first show a deterministic comparison between Oclptx and Probtrackx, proving validity as well as computation speed increase.
* Next, we show the fully probabilistic result of Oclptx using our custom PRNG routine.
* Finally, we present our work on multi-threaded reduction.

We recognize that proving convergence on the probabilistic scenario is necessary to completely prove correctness. While we can produce probablistic results, time did not allow for us to set up the statistical t-tests necessary for validation. Our sponsor has offered to complete this task himself, given that a deterministic match is the critical step.

Deterministic Comparison of Oclptx and Probtrackx
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

To test the convergence of our results with expected behaviour, we modified the source code of Probtrackx (ptx2) such that it does not seed randomly. Instead, we forced ptx2 to seed at a predefined location in the brain mask, and we seeded our Oclptx at that same location in the same data set. Hence, by proving that in this deterministic scenario our interpolation algorithm produces exactly the same set of streamlines as the old code, we prove that our algorithm matches the expected results.

We show these results in :ref:`deterministiccomp`. In this data set, we use 1000 seed points and generated 2000 particles, with a maximum of 2000 steps per path. These parameters give us approximately 4 million points. We then sum over these points to determine the error between the results, :math:`\chi ^ 2`, as follows:

:math:`\chi^2 =  \sum (r^{(1)}_i - r^{(2)}_i)^2  =  O(10^{-11}) \rightarrow  { \langle \chi^2 \rangle } \simeq {O(10^{-13})}`

.. _deterministiccomp:

.. figure:: images/deterministiccomp.pdf

    Deterministic comparison of paths generated by Probtrackx (ptx2) and Oclptx, plotted with Python.


Thus, we have a statistcally negligible error. The differences we have can be accounted for if we consider deviations in how the GPU calculates quantities such as sine or cosine. Fundementally, we have shown that the deterministic results of the two pipelines are identical.

Next, we compare the run time of Oclptx against that of ptx2. For a 4000 particle sample dataset, a deterministic run of ptx2 has an average computation time of **43 seconds** from the point of beginning to interpolate to the point of completion. Oclptx, for the same dataset, has an average tracking time of **500-1500 milliseconds**. The following table compares the two algorithms for various particle sizes.

===========  =========  ===========
Sample Size  Ptx2 Time  Oclptx Time
===========  =========  ===========
4000          43s         1000ms
===========  =========  ===========

    Computation times of Oclptx and Ptx2 compared.

TODO: STEVE This is stuff for you; I wrote to the best of my knowledge and research on our results. You can modify/add as needed. Discuss the significance of the results only within the problem space (not for the greater good of humanity or someshit). NO RECOMMENDATIONS HERE

TODO (steve): going to perform some actual timing benchmarking tonight and include 3-4 plots here.

Probabilistic Results of Oclptx
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

TODO STEVE: Describe the results and show the pictures of the biased tracking. I've already stated in the opening that we don't test against the old PTX2 on this step. Here you can expand on what tests NEED to be done by Danny. NO RECOMMENDATIONS HERE

.. _probibilistic1:

.. figure:: images/probibilistic1.pdf

    Caption here as needed

TODO JEFF: PRNG routine. Describe the results, not much of the process. Your ppt slide has a good level of detail for that. NO RECOMMENDATIONS HERE

.. _prng:

.. figure:: images/prng.png

    Caption here as needed

Multi-Threaded Reduction
^^^^^^^^^^^^^^^^^^^^^^^^

TODO JEFF: If we are at a point to describe integration with Oclptx, then we describe the results of the integration. Focus on Speed and Correctness (compared to the non-multithreaded version). If we are NOT, then the results are the results of your research with collatz. Focus on TEST results. NO RECOMMONDATIONS HERE


